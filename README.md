# datamining

## laba № 1 :
Спарсить данные с канала на YouTube: [репозиторий лабы](https://github.com/lirummirul/Parsing-data-from-YouTube) 

## laba № 2 :
Рассчитать метрики PageRank для выбранного вами любой веб-страницы 

Рассмотреть все ссылки с веб-страницы до 4 уровня включительно (имеется в виду ссылка с веб страницы №1 -> ссылка с веб страницы №2 -> ссылка с веб страницы №3 -> ссылка с веб страницы №4)

DoD: 
показать результаты метрик PageRank, отсортированных по убыванию 
продемонстрировать визуально получившийся граф зависимостей!

**код не оптимизирован, программа работает около 20 минут(

## laba № 3 :
Рассчитать метрики расстояния для любой web страницы для определения категории тематики всей страницы. Сделать очистку от стоп слов / преобразовать в нормальную форму. 

Получить значения метрик схожести между лексемами и набором ключевых слов (ключевые слова необходимо найти в интернете - например используя сервис https://wordstat.yandex.ru/ ) из 4 тематик
- наука
- спорт
- шоппинг
- новости

Рассчитать метрики схожести для двух коэффициентов
- коэффициента Жаккарда 
- метрики Косинуса

DoD: 
Показать что выбранная web страница к какой тематике ближе по расстоянию


## laba № 4 :
Построить оптимальный фильтр Блума на выбранный вами текст (песня, сказка, рассказ, пост). Рассчитайте все необходимые параметры
- количество хэш функций
- длина Блум вектора

  Продемонстрируйте, что фильтр Блума возвращает 0 на указанное слово которого действительного не существует в выбранном тексте и значение для ложноположительного срабатывания для указанного слова, которое существует в тексте


## laba № 5 :

Использовать :
- Линейную регрессию (main.py)
- Полиномиальную регрессию (poli.py)
- SVM (с разными ядерными функциями) (svm.py)
  
Указать зависимость выбранного атрибута от набора других атрибутов. Построить визуализацию, используя библиотеки Matplotlib / Seaborn. По каждому из методов вывести оценку score модели.
